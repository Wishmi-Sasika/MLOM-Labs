{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2wgRszWYi64J11BzmPa++",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wishmi-Sasika/MLOM-Labs/blob/main/MLOM_Lab_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W2eGdrrnc04O"
      },
      "outputs": [],
      "source": [
        "# Importing the needful libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the environment\n",
        "enviroment = gym.make(\"Taxi-v3\").env\n",
        "\n",
        "enviroment.reset()\n",
        "enviroment.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypxXCZWic9Bb",
        "outputId": "ce3c8c72-1a78-4f79-e9e2-4551ded5a032"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
            "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of states & actions\n",
        "print(enviroment.observation_space.n)\n",
        "print(enviroment.action_space.n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsZZkCd2c87H",
        "outputId": "f819c721-818e-4065-94d3-342cec56fb30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the values to the learning rate, the discount factor and epsilon\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1"
      ],
      "metadata": {
        "id": "AXL94rjxc8zb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial Q Table\n",
        "q_table = np.zeros((500,6))\n",
        "q_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMFm6Lgjc8w2",
        "outputId": "898e3512-149d-469d-e19b-89b6021ae8b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Q Table\n",
        "num_of_episodes = 100000\n",
        "\n",
        "for episode in range(0, num_of_episodes):\n",
        "  # Reset the enviroment\n",
        "  state = enviroment.reset()\n",
        "  # Initialize variables\n",
        "  reward = 0\n",
        "  terminated = False\n",
        "\n",
        "  while not terminated:\n",
        "    # Take learned path or explore new actions based on the epsilon\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "      action = enviroment.action_space.sample()\n",
        "    else:\n",
        "      action = np.argmax(q_table[state])\n",
        "\n",
        "    # Take action\n",
        "    next_state, reward, terminated, info = enviroment.step(action)\n",
        "\n",
        "    # Recalculate\n",
        "    q_value = q_table[state, action]\n",
        "    max_value = np.max(q_table[next_state])\n",
        "    new_q_value = (1 - alpha) * q_value + alpha * (reward + gamma * max_value)\n",
        "\n",
        "    # Update Q-table\n",
        "    q_table[state, action] = new_q_value\n",
        "    state = next_state"
      ],
      "metadata": {
        "id": "ZjVFd90Nc8sy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTi90EaVc8q5",
        "outputId": "fc879cd9-c44f-4f1f-d1d3-6d1422c74643"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837063  -2.36395109  -2.41837066  -2.36395109  -2.27325184\n",
            "  -11.36395083]\n",
            " [ -1.87014397  -1.45024058  -1.87014394  -1.45024     -0.7504\n",
            "  -10.45023915]\n",
            " ...\n",
            " [ -1.16521761   0.41599813  -1.19495597  -1.20153361  -2.7390596\n",
            "   -1.93728288]\n",
            " [ -2.14560077  -2.12207601  -2.15896335  -2.12207642  -4.47446943\n",
            "   -4.46676574]\n",
            " [  2.60504334   1.36784516   2.17751968  11.          -1.98286595\n",
            "   -2.27950868]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the goodness of the trained table\n",
        "total_penalties = 0\n",
        "num_of_episodes = 100\n",
        "\n",
        "for _ in range(num_of_episodes):\n",
        "  state = enviroment.reset()\n",
        "  penalties = 0\n",
        "  reward = 0\n",
        "\n",
        "  terminated = False\n",
        "\n",
        "  while not terminated:\n",
        "    action = np.argmax(q_table[state])\n",
        "    state, reward, terminated, info = enviroment.step(action)\n",
        "\n",
        "    if reward <= -10:\n",
        "      penalties += 1\n",
        "\n",
        "  total_penalties += penalties"
      ],
      "metadata": {
        "id": "lrT8FZ9vc8n3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_penalties / num_of_episodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoiyWXUMc8kJ",
        "outputId": "3a7d1231-7253-4ba2-97a2-12a5caafb3ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zBKNSVTAc8hW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}